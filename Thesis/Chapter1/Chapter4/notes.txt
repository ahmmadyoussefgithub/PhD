

If so, then we will declare that in our case revision counts (proxy to change-proneness) can have a confounding impact.
	1. is revision counts change-proneness? Can be argued, yes. 
		http://222.252.30.203:8888/bitstream/123456789/10868/1/Software%20Engineering,%20IEEE%20Transactions.vol.35.Iss.5.A.2.pdf
		In this study, change-proneness denotes the
		extent of change of a class across the versions of the system
		[26], [27]. We need to select a suitable and practical proxy of
		change-proneness as the dependent variable for our study.
		In our study, we use the number of SLOC changes of a
		class from version 2.0 to 2.1 as a proxy of its changeproneness.
		We followed [26], [27] to select this proxy for
		change-proneness. Other possible proxies for changeproneness
		could have been used, such as the number of
		times that a class was modified from version 2.0 to 2.1.
		However, it has been argued that the number of SLOC
		changes can better reflect the extent of modifications as well
		as their frequency [27]

- A lot has been made of the confounding impact of code size on CK metric analysis.
	Not really. They are correlated with 'change-proneness' and 'defects'. Are they correlated with CK metrics? No!
	- What are the relevant papers here?
		- Emam et al
			- https://pdfs.semanticscholar.org/4a73/eb3dabced9f6bb35b13a9a8e2373f64f613c.pdf (Emam et al)
			- Potentially confounding effect of class size. In this paper we demonstrate a strong size confounding effect,
			- We first investigated and found a confounding effect of class size in validation studies of object-oriented metrics 
		- Li and Henry controlled for size when establishing the predictive nature of CK metrics for maintainability. Well, size used as a baseline for predicting 'change' and then CK metrics were found to offer more predictive capability.
		- TSE: Examining the Potentially Confounding Effect of Class Size on the Associations between Object-Oriented Metrics and Change-Proneness (2009)
			- http://ieeexplore.ieee.org/document/4967613/
			- “In this paper, we use three size metrics, two of which are available during the high-level design phase, to examine the potentially confounding effect of class size on the associations between OO metrics and change-proneness. The OO metrics that are investigated include cohesion, coupling, and inheritance metrics.”
		- Pant et al. collected data from a
		set of 69 public domain classes and 25 classes developed for
		their research on the generalization of OO components for
		reuse [25]. They found significant correlations of their
		tested metric with size measures such as SLOC and with
		previously developed complexity measures such as cyclomatic
		complexity [25, p. 26, Table 4].
			.
- In this section we investigate the linear relationship of LOC on CK metrics. We will find that the impact is not substantial in the case of this data set
- We will also investigate the impact of revision counts and we will conclude that there is a substantial correlation between revision counts and CK metrics
	Why?
		- 
- Establishing this will drive the next stage of analysis (multi-variate analysis).

\subsection{Impact of code size on CK metrics}
[TODO] Art discussing this.

Figure ~\ref{fig:AllMetricsAgainstLOC} depicts how  CK metrics trend against code volume showing the average metric values across individual projects against their aggregate Lines of Code (LOC) count. There is no obvious relationship between code volume and the DIT, RFC and WMC metric values; those metrics which capture structural complexity. One explanation for this could be that object-oriented codebases, particularly where well-designed, should have a greater number of classes as code volume increases leading to fairly static average values. 



\subsection{Impact of Revisions on CK metrics}
- What is a revision (covered?)

- The explain for the impact of revision counts.
Throughout the project lifecycle a more functionally complex project will have gone through more iterations of development as more logic is incrementally built out. To elaborate, when using version control systems, it is usual to build functionality iteratively through repeated modification of source files. It has been proven that, as software projects evolve, iterations of a codebase tend to exhibit both growing size and complexity \cite{prather1984axiomatic}. 



\subsection{Revision Counts as a Threat to Validity}
Revisions impact CK metrics
Revisions are correlated with Authors (explain)

This phenomenon is charted in figure ~\ref{fig:RevisionsCommitters} showing that the cumulative number of committers to a project trends positively against the number of revisions that the project has undergone.





\begin{figure}[htbp!] 
\centering    
\includegraphics[width=1.0\textwidth]{RevisionsCommitters.pdf}
\caption{Analysis of the sample projects showing a clear upwards trend of the project revision count against committer count.}
\label{fig:RevisionsCommitters}
\end{figure}

Taking this approach to its logical conclusion, an observation of metrics values in figure ~\ref{fig:MetricsRevisions} demonstrates a clear positive correlation between class revision counts and each of the measures of coupling, cohesion and complexity. This is consistent with the work of Johari et al \cite{johari2012validation} who studied the relationship between CK metrics and revision counts. The lack of observable trends with regards to DIT can be explained by virtue of the fact that this particular metric captures a very specific facet of structural complexity - inheritance complexity - which is not necessarily correlated with broader measures of structural complexity.  These observations are confirmed in Table \ref{tab:LOCRevisionCorrelations} with revision counts showing a stronger Pearson correlation coefficient against RFC and WMC than code volume.

\begin{figure}[htbp!] 
\centering    
\includegraphics[width=1.0\textwidth]{MetricsRevisions.pdf}
\caption{Average metric values at a class level plotted against the cumulative revision count of those files.}
\label{fig:MetricsRevisions}
\end{figure}

\begin{table}
\centering 
\captionof{table}{Correlations and siginficance between the CK Metrics and, individually, Revisions and Lines of Code. DIT, RFC and WMC are highlighted as these capture functional complexity.}
\begin{tabular}
 \centering 
  \includegraphics[width=1.0\textwidth]{LOCRevisionCorrelations.pdf}
 \label{tab:LOCRevisionCorrelations}
\end{tabular}
\end{table}












\begin{figure}[htbp!] 
\centering    
\includegraphics[width=1.0\textwidth]{MetricsRevisions.pdf}
\caption{Average metric values at a class level plotted against the cumulative revision count of those files.}
\label{fig:MetricsRevisions}
\end{figure}


TODO - a real and tangible threat to validity applicable to the previous section. 
	- Reference correlation between author and revisions in previous section
	- the graph showing authors and revisions
- Understanding the relationship between revisions and metrics
	- the graph
- Understanding what revision counts represent
	- Correlation between total commits and functional tickets
	- Here is where we could really put some of our functional complexity stuff.



















\section{Factoring in Functional Complexity} %Section - 4.5 
To date in this thesis, references to \textit{complexity} have, in fact, alluded to \textit{structural complexity}. This was defined earlier as the measure of the degree of interactions between components in a software system. This is in contrast to functional complexity which has no single definition but generally refers to the degree of sophistication in the logic encoded within a software system.  The analysis of the previous section simplistically considered the impact of team size without consideration of the fact that codebases with a larger team size are more likely to exhibit higher functional complexity than codebases with fewer committers due to the fact that the larger team is more likely to work on more functionally rich solutions. 

[TODO this is not proven. Cant find art to back this up. Can look to prove?]

Models using committer count as a single independent 'predictor' variable to CK metrics may, infact, by driven by the increased \textit{functional complexity} which accompanies increased committer count; not necessarily through influences on the team dynamics but rather owing to the fact that larger teams will solve for more complex problems. It was established in previous research that \textit{functional complexity} and \textit{structural complexity} are correlated \cite{braha1998measurement}. Given that DIT, RFC, and WMC capture aspects of structural complexity, this poses a threat to the validity of the aforementioned linear model.

In this section a mechanism is established to track functional complexity which underpin a methodological approach to isolate the impact of team size on the structural metrics to the exclusion of the impact of functional complexity.


\subsection{Direct measures of functional complexity}
TODO


\subsection{Identifying a proxy to functional complexity}
Measuring design complexity is a fairly straightforward task. Structural metrics such as CK's RFC and WMC capture design complexity - to make no mention of Halstead or McCabe's complexity metrics which are specifically designed for this purpose. Conversely capturing functional complexity is notoriously more difficult.  Several measures have been proposed, generally with a tendency to conflate functional and structural complexity through attempts to track the nature of control structures within the source code or interactions between components. It is understandable that code inspection would be the default approach to measuring functional complexity as, where requirements are documented, they are often fragmented and therefore difficult interpret in an automated fashion.

One possible approach for tracking functional complexity is to measure code volume and hold this variable as static as reasonably possible through the analysis process. That approach was formulated through research designed to identify fault-prone classes and was based on the notion that larger classes were more likely to exhibit faults \cite{subramanyam2003empirical}\cite{el2001prediction}. Figure ~\ref{fig:MetricVersusLOC} depicts how those CK metrics that capture structural complexity trend against code volume showing the average metric values across individual projects against their aggregate Lines of Code (LOC) count. Despite the relationship between functional complexity and structural complexity, there is no obvious relationship between code volume and the DIT, RFC and WMC metric values; those metrics which capture structural complexity. One explanation for this could be that object-oriented codebases, particularly where well-designed, should have a greater number of classes as code volume increases leading to fairly static average values. 

\begin{figure}[htbp!] 
\centering    
\includegraphics[width=1.0\textwidth]{MetricVersusLOC.pdf}
\caption{Average project-level structural metric values plotted against the cumulative Lines of Code for that project.}
\label{fig:MetricVersusLOC}
\end{figure}

It is necessary to determine a more appropriate proxy to functional complexity; one that is not based on the structural attributes of the software given that this is the subject of the study and therefore not a suitable control factor. The meta-data captured within version control systems can be helpful in this respect. Throughout the project lifecycle a more functionally complex project will have gone through more iterations of development as more logic is incrementally built out. To elaborate, when using version control systems, it is usual to build functionality iteratively through repeated modification of source files. It has been proven that, as software projects evolve, iterations of a codebase tend to exhibit both growing size and complexity \cite{prather1984axiomatic}. This phenomenon is charted in Figure ~\ref{fig:RevisionsCommitters} showing that the cumulative number of committers to a project trends positively against the number of revisions that the project has undergone.

\begin{figure}[htbp!] 
\centering    
\includegraphics[width=1.0\textwidth]{RevisionsCommitters.pdf}
\caption{Analysis of the sample projects showing a clear upwards trend of the project revision count against committer count.}
\label{fig:RevisionsCommitters}
\end{figure}

Taking this approach to its logical conclusion, an observation of metrics values in Figure ~\ref{fig:MetricsRevisions} demonstrates a clear positive correlation between class revision counts and each of the measures of coupling, cohesion and complexity. This is consistent with the work of Johari et al \cite{johari2012validation} who studied the relationship between CK metrics and revision counts. The lack of observable trends with regards to DIT can be explained by virtue of the fact that this particular metric captures a very specific facet of structural complexity - inheritance complexity - which is not necessarily correlated with broader measures of structural complexity.  These observations are confirmed in Table \ref{tab:LOCRevisionCorrelations} with revision counts showing a stronger Pearson correlation coefficient against RFC and WMC than code volume.

\begin{figure}[htbp!] 
\centering    
\includegraphics[width=1.0\textwidth]{MetricsRevisions.pdf}
\caption{Average metric values at a class level plotted against the cumulative revision count of those files.}
\label{fig:MetricsRevisions}
\end{figure}

\begin{table}
\centering 
\captionof{table}{Correlations and siginficance between the CK Metrics and, individually, Revisions and Lines of Code. DIT, RFC and WMC are highlighted as these capture functional complexity.}
\begin{tabular}
 \centering 
  \includegraphics[width=1.0\textwidth]{LOCRevisionCorrelations.pdf}
 \label{tab:LOCRevisionCorrelations}
\end{tabular}
\end{table}

Given the relationship between structural complexity and functional complexity, the trends observed in Figure ~\ref{fig:MetricsRevisions} can be taken as evidence of the utility of revision count as proxy for functional complexity. Furthermore, the fact that revisions are tagged with comments which often refer explicitly to additional functionality (alongside more sparse comments around refactoring or bug fixes), it is logical and intuitive that revision counts would be a proxy to functional complexity. An example of this can be seen in Figure ~\ref{fig:PreciseRevisionLogs} which is an excerpt from the revision logs from a project called 'Precise', a requirements management tool, which will be studied in more detail in a later chapter. 

\begin{figure}[htbp!] 
\centering    
\includegraphics[width=1.0\textwidth]{PreciseRevisionLogs.pdf}
\caption{An excerpt of the revision log from the 'precise' project showing commentary explaining the addition of functional complexity with each revision.}
\label{fig:PreciseRevisionLogs}
\end{figure}

